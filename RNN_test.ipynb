{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [02:41<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "# import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "# from tensorflow.keras import models\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "data_size = len(data['Id'])\n",
    "data[\"Country_Region\"] = [country_name.replace(\"'\",\"\") for country_name in data[\"Country_Region\"]]\n",
    "data = data.query(\"Date>'2020-01-29' and Date<='2020-03-11'\")\n",
    "trend_df = pd.DataFrame(columns={\"infection_trend\",\"fatality_trend\",\"expected_cases\",\"expected_fatalities\"})\n",
    "\n",
    "# for country in data.Country_Region.unique():\n",
    "#     print(country)\n",
    "\n",
    "    # count = 0\n",
    "    # for province in data.query(\"Country_Region=='\"+country+\"'\").Province_State:\n",
    "    #     count+=1\n",
    "\n",
    "    # print(count)\n",
    "tensor_size = 7\n",
    "with tqdm(total=len(data.Country_Region.unique())) as pbar:\n",
    "    for country in data.Country_Region.unique():\n",
    "        for province in data.query(\"Country_Region=='\"+country+\"'\").Province_State:\n",
    "            province_df = data.query(\"Country_Region=='\"+country+\"' and Province_State=='\"+str(province)+\"'\")\n",
    "            for i in range(0,len(province_df)-tensor_size,tensor_size):\n",
    "\n",
    "                infection_trend = [float(x) for x in province_df[i:i+tensor_size-1].ConfirmedCases.values]\n",
    "                fatality_trend = [float(x) for x in province_df[i:i+tensor_size-1].Fatalities.values]\n",
    "                expected_cases = float(province_df.iloc[i+tensor_size-1].ConfirmedCases)\n",
    "                expected_fatalities = float(province_df.iloc[i+tensor_size-1].Fatalities)\n",
    "                                            \n",
    "                trend_df = trend_df.append({\"infection_trend\":infection_trend,\n",
    "                                 \"fatality_trend\":fatality_trend,\n",
    "                                 \"expected_cases\":expected_cases,\n",
    "                                 \"expected_fatalities\":expected_fatalities},ignore_index=True)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infection_trend  expected_fatalities  \\\n",
      "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]                  0.0   \n",
      "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]                  0.0   \n",
      "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]                  0.0   \n",
      "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]                  0.0   \n",
      "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]                  0.0   \n",
      "...                               ...                  ...   \n",
      "26245  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]                  0.0   \n",
      "26246  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]                  0.0   \n",
      "26247  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]                  0.0   \n",
      "26248  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]                  0.0   \n",
      "26249  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]                  0.0   \n",
      "\n",
      "                       fatality_trend  expected_cases  \\\n",
      "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]             0.0   \n",
      "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]             0.0   \n",
      "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]             0.0   \n",
      "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]             0.0   \n",
      "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]             0.0   \n",
      "...                               ...             ...   \n",
      "26245  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]             0.0   \n",
      "26246  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]             0.0   \n",
      "26247  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]             0.0   \n",
      "26248  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]             0.0   \n",
      "26249  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]             0.0   \n",
      "\n",
      "                                                   input  \n",
      "0      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
      "1      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
      "2      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
      "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
      "4      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
      "...                                                  ...  \n",
      "26245  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
      "26246  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
      "26247  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
      "26248  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
      "26249  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
      "\n",
      "[26250 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(trend_df)\n",
    "trend_df[\"input\"] = [np.asarray([np.array(trends[\"infection_trend\"]),np.asarray(trends[\"fatality_trend\"])]) for idx,trends in trend_df.iterrows()]\n",
    "print(trend_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>infection_trend</th>\n",
       "      <th>expected_fatalities</th>\n",
       "      <th>fatality_trend</th>\n",
       "      <th>expected_cases</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>[4903.0, 5806.0, 7153.0, 11177.0, 13522.0, 166...</td>\n",
       "      <td>549.0</td>\n",
       "      <td>[162.0, 204.0, 249.0, 350.0, 414.0, 479.0]</td>\n",
       "      <td>19665.0</td>\n",
       "      <td>[[4903.0, 5806.0, 7153.0, 11177.0, 13522.0, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9761</th>\n",
       "      <td>[79.0, 81.0, 88.0, 91.0, 95.0, 106.0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 2.0]</td>\n",
       "      <td>112.0</td>\n",
       "      <td>[[79.0, 81.0, 88.0, 91.0, 95.0, 106.0], [1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10469</th>\n",
       "      <td>[174.0, 174.0, 174.0, 174.0, 174.0, 174.0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0]</td>\n",
       "      <td>174.0</td>\n",
       "      <td>[[174.0, 174.0, 174.0, 174.0, 174.0, 174.0], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12093</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10689</th>\n",
       "      <td>[1205.0, 1205.0, 1205.0, 1205.0, 1206.0, 1213.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>[[1205.0, 1205.0, 1205.0, 1205.0, 1206.0, 1213...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         infection_trend  expected_fatalities  \\\n",
       "6515   [4903.0, 5806.0, 7153.0, 11177.0, 13522.0, 166...                549.0   \n",
       "9761               [79.0, 81.0, 88.0, 91.0, 95.0, 106.0]                  2.0   \n",
       "10469         [174.0, 174.0, 174.0, 174.0, 174.0, 174.0]                  2.0   \n",
       "12093                     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]                  0.0   \n",
       "10689   [1205.0, 1205.0, 1205.0, 1205.0, 1206.0, 1213.0]                  1.0   \n",
       "\n",
       "                                   fatality_trend  expected_cases  \\\n",
       "6515   [162.0, 204.0, 249.0, 350.0, 414.0, 479.0]         19665.0   \n",
       "9761               [1.0, 1.0, 1.0, 1.0, 1.0, 2.0]           112.0   \n",
       "10469              [2.0, 2.0, 2.0, 2.0, 2.0, 2.0]           174.0   \n",
       "12093              [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]             0.0   \n",
       "10689              [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]          1213.0   \n",
       "\n",
       "                                                   input  \n",
       "6515   [[4903.0, 5806.0, 7153.0, 11177.0, 13522.0, 16...  \n",
       "9761   [[79.0, 81.0, 88.0, 91.0, 95.0, 106.0], [1.0, ...  \n",
       "10469  [[174.0, 174.0, 174.0, 174.0, 174.0, 174.0], [...  \n",
       "12093  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0....  \n",
       "10689  [[1205.0, 1205.0, 1205.0, 1205.0, 1206.0, 1213...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "trend_df = shuffle(trend_df)\n",
    "trend_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(columns={\"infection_trend\",\"fatality_trend\",\"expected_cases\",\"expected_fatalities\"})\n",
    "count = 0\n",
    "for i, row in trend_df.iterrows():\n",
    "    if(sum(row.infection_trend) > 0):\n",
    "        temp = temp.append(row)\n",
    "    else:\n",
    "        if(i < 2000):\n",
    "            temp = temp.append(row)\n",
    "            i+=1\n",
    "trend_df = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_percentage = 0.8\n",
    "training_count = int(len(trend_df)*training_percentage)\n",
    "validation_count = len(trend_df)-training_count\n",
    "training_df = trend_df[:training_count]\n",
    "validation_df = trend_df[training_count:]\n",
    "\n",
    "X_train = np.asarray(np.reshape(np.asarray([np.asarray(x) for x in training_df[\"input\"]]),(training_count,2,tensor_size-1))).astype(np.float32)\n",
    "Y_cases_train = np.asarray([np.asarray(x) for x in training_df[\"expected_cases\"]]).astype(np.float32)\n",
    "Y_fatalities_train = np.asarray([np.asarray(x) for x in training_df[\"expected_fatalities\"]]).astype(np.float32)\n",
    "\n",
    "X_test = np.asarray(np.reshape(np.asarray([np.asarray(x) for x in validation_df[\"input\"]]),(validation_count,2,tensor_size-1))).astype(np.float32)\n",
    "Y_cases_test = np.asarray([np.asarray(x) for x in validation_df[\"expected_cases\"]]).astype(np.float32)\n",
    "Y_fatalities_test = np.asarray([np.asarray(x) for x in validation_df[\"expected_fatalities\"]]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('keras-gpu': conda)",
   "name": "python37664bitkerasgpuconda5063b82eac224514952264ee20e6be1d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
